{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ASSIGNMENT 1                                                McGill:COMP766-2 - Winter 2021 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import networkx as nx\n",
    "from utils import tensor_mult"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 1. (5 points)\n",
    "\n",
    "- __a__: 2 points) Derive the __Markov__ inequality below for a positive discrete random variable\n",
    "(_Hint:_ rearrange to prove $a P(x \\geq a) \\leq \\mathbb{E}[X]$ and substitute the definition of expectation.)\n",
    "$$P(x > a) \\leq \\frac{\\mathbb{E}[X]}{a}$$\n",
    "- __b__: 3 points) Using this inequality prove the following, known as __Chebyshev__ inequality:\n",
    "$$P(|X - \\mathbb{E}[X]| > a) < \\frac{Var(X)}{a^2}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution\n",
    "__a__) At first we calculate $ \\mathbb{E}[X] $ :\n",
    "\n",
    "$$\\mathbb{E}[X] = \\sum_x xp(x) = \\sum_{x < a} xp(x) + \\sum_{x \\geq a} xp(x)$$\n",
    "\n",
    "$$\\Rightarrow \\mathbb{E}[X] \\geq \\sum_{x \\geq a} xp(x)dx  \\geq \\sum_{x \\geq a} ap(x)dx = a\\sum_{x \\geq a} p(x)dx$$\n",
    "\n",
    "$$\\Rightarrow \\mathbb{E}[X] \\geq a\\sum_{x \\geq a} p(x)dx = a(P(x\\geq a)$$\n",
    "\n",
    "$$\\Rightarrow P(x \\geq a) \\leq \\frac{\\mathbb{E}[X]}{a}$$\n",
    "\n",
    "__b__) We can assume that $x = (X-\\mathbb{E}[X])^2$ and $ a=a^2$ in from previous inequality:\n",
    "\n",
    "We know that: $$P((X-\\mathbb{E}[X])^2>a^2) = P(|X-\\mathbb{E}[X]|>a)$$\n",
    "\n",
    "Therefore:\n",
    "$$P((X-\\mathbb{E}[X])^2>a^2) \\leq \\frac{\\mathbb{E}[(X-\\mathbb{E}[X])^2]}{a^2}$$\n",
    "\n",
    "$$ \\Rightarrow P(|X-\\mathbb{E}[X]|>a) \\leq \\frac{\\mathbb{E}[(X-\\mathbb{E}[X])^2]}{a^2}$$\n",
    "\n",
    "$$ \\Rightarrow P(|X-\\mathbb{E}[X]|>a) \\leq \\frac{Var(X)}{a^2}$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 2. (5 points)\n",
    "\n",
    "In showing that factorization in a Markov Network leads to local CIs we used the\n",
    "following fact. Prove it using the definition of conditional independence:\n",
    "\n",
    "$$\n",
    "P \\models (X \\perp Y \\mid Z) \\quad \\Leftrightarrow \\quad P(X=x, Y=y, Z=z) = f(x, z)g(y,z) \n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution\n",
    "\n",
    "- $\\Rightarrow$) 2 points \n",
    "\n",
    "We know that: $$P \\models (X \\perp Y \\mid Z) \\Leftrightarrow P(X,Y|Z) = P(X|Z)P(Y|Z)$$\n",
    "\n",
    "From chain rule we have: $$P(X,Y,Z) = P(X,Y|Z)P(Z)$$\n",
    "\n",
    "Therefore: $$\\Rightarrow P(X,Y,Z) = P(X|Z)P(Y|Z)P(Z) = P(X|Z)P(Y,Z) $$\n",
    "\n",
    "So now we have two factors, $P(X=x|Z=z)$ or we can consider it as $f(x,z)$ and $P(Y=y,Z=z)$ or we can consider it as $g(y,z)$.\n",
    "\n",
    "Therefore: $$P(X=x,Y=y,Z=z) = f(x,z)g(y,z)$$\n",
    "\n",
    "\n",
    "- $\\Leftarrow$) 3 points\n",
    "\n",
    "We can calculate $P(X|Z)$ and $P(Y|Z)$ separately: \n",
    "\n",
    "$$P(X,Z) = \\sum_Y P(X,Y,Z) = \\sum_{y \\in Y} f(x,z)g(y,z) = f(x,z)\\sum_{y \\in Y} g(y,z) $$\n",
    "\n",
    "$$P(Y,Z) = \\sum_Y P(X,Y,Z) = \\sum_{x \\in X} g(y,z)f(x,z) = g(y,z)\\sum_{x \\in X} f(x,z) $$\n",
    "\n",
    "$$P(Z) = \\sum_X \\sum_Y P(X,Y,Z) = \\sum_{x \\in X} \\sum_{y \\in Y} f(x,z)g(y,z) = \\sum_{x \\in X} f(x,z) \\sum_{y \\in Y} g(y,z)$$\n",
    "\n",
    "$$\\Rightarrow P(X|Z) = \\frac{P(X,Z)}{P(Z)} =\\frac{f(x,z)\\sum_{y \\in Y} g(y,z)}{\\sum_{x \\in X} f(x,z) \\sum_{y \\in Y} g(y,z)} = \\frac{f(x,z)}{\\sum_{x \\in X} f(x,z)}$$\n",
    "\n",
    "$$\\Rightarrow P(X|Z) = \\frac{P(X,Z)}{P(Z)} =\\frac{g(y,z)\\sum_{x \\in X} g(y,z)}{\\sum_{x \\in X} f(x,z) \\sum_{y \\in Y} g(y,z)} = P(Y|Z) = \\frac{g(y,z)}{\\sum_{y \\in Y} g(y,z)}$$\n",
    "\n",
    "$P(X,Y|Z)$ can be written as: $$P(X,Y|Z) = \\frac{P(X,Y,Z)}{P(Z)} = \\frac{f(x,z)g(y,z)}{\\sum_{x \\in X} f(x,z) \\sum_{y \\in Y} g(y,z)} = \\frac{f(x,z)}{\\sum_{x \\in X} f(x,z)} \\frac{g(y,z)}{\\sum_{y \\in Y} g(y,z)} = P(X|Z)P(Y|Z)$$\n",
    "\n",
    "Therefore: $$P \\models (X \\perp Y \\mid Z)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 3. (10 points)\n",
    "\n",
    "Here, we want to represent the joint probability $P(D,I,G,S,L)$ and answer arbitrary queries such as $P(D,I \\mid G=0, L=1)$ for the running example below that we used extensively in the class.\n",
    "<img src=\"3_4.png\" width=\"400\">\n",
    "For this, we need to define CPTs. We use the ```networkx``` package to represent a DAG and add CPTs as node attributes. the CPT for a node with $K$ parents is a $K+1$ dimensional array, where the first dimension is for the child node and the order of parents follows their order when the method ```DAG.predecessors(node)``` is called. This is the order in which the corresponding edges are added. \n",
    "\n",
    "Your task is to write the body of the function ```Pr()``` that calculates the array of the posterior marginal, given a DAG -- e.g., $P(D, L \\mid G= 2, I = 1)$. \n",
    "For your implementation you can use the ```tensor_mult``` helper function provided in ```utility.py```. \n",
    "\n",
    "You can try implementing this function in three steps:\n",
    "\n",
    "- calculate the joint PMF\n",
    "- condition on the evidence (e.g., by multiplying the joint array with appropriate tensor of 0s and 1s.\n",
    "- marginalize and normalize the final results (normalization might be necessary depending on your implementation of conditioning on the evidence)\n",
    "\n",
    "There are more efficient ways of calculating the posterior marginals that we study in the __inference__ lectures.\n",
    "\n",
    "### Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is this a DAG? True\n",
      "Result is is [0.92105263 0.07894737]\n"
     ]
    }
   ],
   "source": [
    "# creating the BayesNet\n",
    "BN = nx.DiGraph()\n",
    "BN.add_node('D', cpt=np.array([.6,.4]))\n",
    "BN.add_node('I', cpt=np.array([.7,.3]))\n",
    "\n",
    "#a 3-dimensional array of shape 3x2x2 representing P(G|I,D).  \n",
    "#note that the order of parents matters, here we have made sure the order is the same as\n",
    "#the order returned by BN.predecessors('G')\n",
    "BN.add_node('G', cpt=np.array([[[.3,.05],[.9,.5]],[[.4,.25],[.08,.3]],[[.3,.7],[.02,.2]]]))\n",
    "BN.add_node('L', cpt=np.array([[.1,.4,.99],[.9,.6,.01]]))\n",
    "BN.add_node('S', cpt=np.array([[.95,.2],[.05,.8]]))\n",
    "\n",
    "# adding edges (note that the order of I,D -> G is important)\n",
    "BN.add_edge('I','G')\n",
    "BN.add_edge('D','G')\n",
    "BN.add_edge('G', 'L')\n",
    "BN.add_edge('I', 'S')\n",
    "\n",
    "print(\"Is this a DAG? {}\".format(nx.is_directed_acyclic_graph(BN)))\n",
    "# we can use topological sort to get a topological ordering of nodes. What is the complexity of this sorting op.?\n",
    "#The complexity would be O(V+E), since DFS traveral is used to sort the nodes.\n",
    "\n",
    "list(nx.topological_sort(BN))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def Pr(target, \n",
    "       evidence, # a dictionary of observations to conditin on -- eg, {'L':0, 'I':1}\n",
    "       DAG #DAG containing the CPTs (BN above)\n",
    "      ):\n",
    "    \n",
    "    sorted_BN = list(nx.topological_sort(BN))\n",
    "    cpt = nx.get_node_attributes(BN, \"cpt\")\n",
    "    \n",
    "    # creating the tensor of joint probabilities \n",
    "    Prob = cpt[sorted_BN[0]]\n",
    "    visited = []\n",
    "    visited.append(sorted_BN[0])\n",
    "    for node in sorted_BN[1:]:\n",
    "        axis1 = []\n",
    "        axis2 = []\n",
    "        if ( set(visited) & set(BN.predecessors(node)) == set(BN.predecessors(node)) and len(list(BN.predecessors(node)))>0):\n",
    "            i = 1\n",
    "            for p in list(BN.predecessors(node)):\n",
    "                axis1.append(visited.index(p))\n",
    "                axis2.append(i)\n",
    "                i +=1\n",
    "        Prob = tensor_mult(Prob, cpt[node], axis1, axis2)\n",
    "        visited.append(node)      \n",
    "    P = Prob\n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "    #Calculating the margin of non evidences\n",
    "    evidence_keys = list((evidence.keys()))\n",
    "    evidence_values = list((evidence.values()))\n",
    "    margin_denum = P.copy()\n",
    "    margin_axises = []\n",
    "    margin_values = []\n",
    "    ax = 0\n",
    "    for i,node in enumerate(sorted_BN):\n",
    "        if node not in evidence_keys:\n",
    "            margin_axises.append(ax)\n",
    "            margin_denum = margin_denum.sum(axis=ax)\n",
    "            \n",
    "        else:\n",
    "            ax += 1\n",
    "            margin_values.append(evidence[node]) #topological sorting evidence values\n",
    "    \n",
    "    \n",
    "    \n",
    "    #Calculating the margin of joint prbability of target and evidences\n",
    "    joint_axises = []\n",
    "    join_nodes = []\n",
    "    margin_joint = P.copy()\n",
    "    ax = 0\n",
    "    for i,node in enumerate(sorted_BN):\n",
    "        if node not in evidence_keys and node not in target:\n",
    "            joint_axises.append(ax)\n",
    "            margin_joint = margin_joint.sum(axis=ax)\n",
    "            \n",
    "        else:\n",
    "            ax += 1\n",
    "            join_nodes.append(node)\n",
    "\n",
    "    #calculating the margin given the evidence values\n",
    "    idx = 0  \n",
    "    for i,node in enumerate(join_nodes):\n",
    "        if node in evidence_keys:\n",
    "            margin_joint = margin_joint.take(indices=evidence[node],axis=idx)\n",
    "        else:\n",
    "            idx +=1\n",
    "    ax = 0  \n",
    "    topologiacal_order_axis = []\n",
    "    input_order = []\n",
    "    target_sorted = []\n",
    "    for node in sorted_BN:\n",
    "        if node in target:\n",
    "            target_sorted.append(node)\n",
    "            input_order.append(target.index(node))\n",
    "            topologiacal_order_axis.append(ax)\n",
    "            ax +=1\n",
    "    \n",
    "    #sorting the result based on order of target\n",
    "    for i in topologiacal_order_axis:\n",
    "        if (topologiacal_order_axis == input_order):\n",
    "            break;\n",
    "        if (i != target.index(target_sorted[i])):\n",
    "            margin_joint = np.swapaxes(margin_joint, i, target.index(target_sorted[i]))\n",
    "            topologiacal_order_axis[i], topologiacal_order_axis[target.index(target_sorted[i])] = topologiacal_order_axis[target.index(target_sorted[i])], topologiacal_order_axis[i]\n",
    " \n",
    "            \n",
    "    \n",
    "    marginal = margin_joint/margin_joint.sum()\n",
    "    return marginal\n",
    "\n",
    "\n",
    "\n",
    "evidence = {'L':0,'G':2} \n",
    "target = ['I']\n",
    "\n",
    "res = Pr(target,evidence,BN)\n",
    "print(\"Result is is\",res)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 4. (10 points)\n",
    "\n",
    "Your task in this assignment is to implement __D-separation__ algorithm for a DAG representation, similar to what we used in the previous problem. Note that (assuming non-deterministic factors) D-separation does not need access to the CPTs. The following function returns ```True``` if the given CI holds and ```False``` otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "def is_collider(X,Y,Z,DAG):\n",
    "    return (X in BN.predecessors(Z)) and (Y in BN.predecessors(Z))\n",
    "\n",
    "def is_cond_independent(X, #non-empty list of nodes -- e.g., ['I', 'D'] \n",
    "                        Y, #non-empty list of nodes. It has no intersection with X -- e.g., ['S']\n",
    "                        Z, #list of nodes -- e.g., []\n",
    "                        DAG #networkx DAG -- e.g., BN defined above\n",
    "                       ):\n",
    "    is_CI = False\n",
    "    \n",
    "    #BFS traversal\n",
    "    mark = list(Z)\n",
    "    for z in Z:\n",
    "        if len(list(BN.successors(z)))==0 and len(list(BN.predecessors(z)))==1 and list(BN.predecessors(z))[0] not in mark:\n",
    "            mark = mark + list(BN.predecessors(z)) \n",
    " \n",
    "        \n",
    "    visited = []\n",
    "    \n",
    "    for x in X: \n",
    "        for y in Y: \n",
    "            paths = list(nx.all_simple_paths(BN.to_undirected(),x,y))\n",
    "            for path in paths:\n",
    "                for i,v in enumerate(path):\n",
    "                    if (i>0 and i<len(path)-1):\n",
    "                        if(v == y):\n",
    "                            is_CI = False\n",
    "\n",
    "                        if (is_collider(path[i-1],path[i+1],v,BN) and v not in mark) or (not is_collider(path[i-1],path[i+1],v,BN) and v in mark):\n",
    "                            is_CI = True\n",
    "        \n",
    "        return is_CI;\n",
    "\n",
    "ci = is_cond_independent('D','L',['G'],BN)\n",
    "print(ci)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us verify that the CIs that we get from D-separation, match the definition of conditional independence using the conditional probabilities that we can numerically calculate using your solution to the problem 3. \n",
    "In the following we look at all queries in the form of $P \\overset{?}{\\models} {D} \\perp {S} \\mid \\mathbf{Z} = \\mathbf{0}$, where $\\mathbf{Z} \\subseteq \\{I,G,L\\}$ may contain any of the remaining variables. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "passed the minimal test\n"
     ]
    }
   ],
   "source": [
    "domains = {'I':[0,1], 'L':[0,1], 'G':[0,1,2]}\n",
    "for Z in [{},{'I':0}, {'G':0}, {'L':0}, {'I':0,'G':0}, {'I':0,'L':0}, {'L':0,'G':0}, {'I':0,'G':0,'L':0}]:\n",
    "    #conditional independence from D-separation\n",
    "    CI_alg = is_cond_independent(['D'], ['S'], Z.keys(), BN)\n",
    "    #conditional independence according to conditional probabilities\n",
    "    CI_num = np.max(np.abs(Pr(['D','S'], Z, BN) - np.outer(Pr(['D'], Z, BN),Pr(['S'], Z, BN)))) < 1e-10\n",
    "    #they should match\n",
    "    assert(CI_num == CI_alg)\n",
    "print(\"passed the minimal test\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
